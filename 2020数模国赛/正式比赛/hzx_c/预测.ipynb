{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_data = pd.read_excel('data.xlsx', sheet_name='Sheet1',\n",
    "                           index_col=None, header=None)\n",
    "pre_data = pd.read_excel('data.xlsx', sheet_name='Sheet2',\n",
    "                         index_col=None, header=None)\n",
    "train_data = train_data.values\n",
    "pre_data = pre_data.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "# 分离训练数据x和y\n",
    "train_data_y = train_data[:, 0]\n",
    "train_data_x = train_data[:, 1:]\n",
    "\n",
    "# 归一化处理x，所有指标归至（0，1）\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data_x = scaler.fit_transform(train_data_x)\n",
    "pre_data = np.nan_to_num(pre_data)\n",
    "pre_data_x = scaler.transform(pre_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 64)                2176      \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,161\n",
      "Trainable params: 19,521\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 模型\n",
    "network = keras.models.Sequential()\n",
    "network.add(keras.layers.Dense(64, input_shape=(train_data_x.shape[1], )))\n",
    "network.add(keras.layers.ReLU())\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(keras.layers.Dense(64))\n",
    "network.add(keras.layers.ReLU())\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(keras.layers.Dense(64))\n",
    "network.add(keras.layers.ReLU())\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(keras.layers.Dense(64))\n",
    "network.add(keras.layers.ReLU())\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(keras.layers.Dense(64))\n",
    "network.add(keras.layers.ReLU())\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(keras.layers.Dense(1))\n",
    "\n",
    "print(network.summary())\n",
    "network.compile(optimizer=keras.optimizers.RMSprop(lr=1e-3),\n",
    "                loss=keras.losses.mean_squared_error,\n",
    "                metrics=[keras.metrics.mean_absolute_error])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104 samples, validate on 19 samples\n",
      "Epoch 1/20\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 4.5119 - mean_absolute_error: 1.3917 - val_loss: 3.0831 - val_mean_absolute_error: 1.6484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "104/104 [==============================] - 0s 321us/step - loss: 1.6616 - mean_absolute_error: 0.9029 - val_loss: 3.2899 - val_mean_absolute_error: 1.7046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 0s 307us/step - loss: 1.6746 - mean_absolute_error: 1.0015 - val_loss: 3.3316 - val_mean_absolute_error: 1.7159\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 0s 316us/step - loss: 0.9363 - mean_absolute_error: 0.7634 - val_loss: 3.3175 - val_mean_absolute_error: 1.7125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 0s 336us/step - loss: 1.1172 - mean_absolute_error: 0.8274 - val_loss: 3.2683 - val_mean_absolute_error: 1.6993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 0s 288us/step - loss: 0.8800 - mean_absolute_error: 0.7576 - val_loss: 3.1851 - val_mean_absolute_error: 1.6770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 0s 326us/step - loss: 1.0038 - mean_absolute_error: 0.7433 - val_loss: 3.2437 - val_mean_absolute_error: 1.6932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 0s 316us/step - loss: 0.7623 - mean_absolute_error: 0.6851 - val_loss: 3.2800 - val_mean_absolute_error: 1.7026\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 0s 307us/step - loss: 0.8736 - mean_absolute_error: 0.7527 - val_loss: 3.1305 - val_mean_absolute_error: 1.6621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 0s 316us/step - loss: 0.6509 - mean_absolute_error: 0.6325 - val_loss: 3.0478 - val_mean_absolute_error: 1.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 0s 374us/step - loss: 0.7446 - mean_absolute_error: 0.6693 - val_loss: 3.1458 - val_mean_absolute_error: 1.6654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 0s 316us/step - loss: 0.6299 - mean_absolute_error: 0.6574 - val_loss: 3.1963 - val_mean_absolute_error: 1.6790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 0s 326us/step - loss: 0.8193 - mean_absolute_error: 0.6831 - val_loss: 3.1997 - val_mean_absolute_error: 1.6798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 0s 297us/step - loss: 0.8075 - mean_absolute_error: 0.7315 - val_loss: 3.2606 - val_mean_absolute_error: 1.6959\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 0s 326us/step - loss: 0.7079 - mean_absolute_error: 0.6172 - val_loss: 3.1887 - val_mean_absolute_error: 1.6764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 0s 316us/step - loss: 0.7683 - mean_absolute_error: 0.6804 - val_loss: 3.1250 - val_mean_absolute_error: 1.6589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "104/104 [==============================] - 0s 326us/step - loss: 0.5500 - mean_absolute_error: 0.5940 - val_loss: 3.1422 - val_mean_absolute_error: 1.6634\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "104/104 [==============================] - 0s 336us/step - loss: 0.5940 - mean_absolute_error: 0.6131 - val_loss: 3.1210 - val_mean_absolute_error: 1.6572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "104/104 [==============================] - 0s 336us/step - loss: 0.6554 - mean_absolute_error: 0.6567 - val_loss: 3.1849 - val_mean_absolute_error: 1.6743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "104/104 [==============================] - 0s 316us/step - loss: 0.5567 - mean_absolute_error: 0.5653 - val_loss: 3.1756 - val_mean_absolute_error: 1.6721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(x=train_data_x, y=train_data_y,\n",
    "                      epochs=20,\n",
    "                      batch_size=32,\n",
    "                      validation_split=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = history.history\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "epoch = range(1, len(loss) + 1)\n",
    "\n",
    "# 绘制loss趋势图\n",
    "ax_loss = plt.figure(figsize=(9, 9)).gca()\n",
    "ax_loss.plot(epoch, loss, color='b', marker='>', linestyle='-', label='Loss')\n",
    "ax_loss.plot(epoch, val_loss, color='r', marker='o', linestyle=':', label='Vla_Loss')\n",
    "ax_loss.set_title('Loss')\n",
    "ax_loss.set_xlabel('epoch')\n",
    "ax_loss.set_ylabel('loss')\n",
    "ax_loss.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}