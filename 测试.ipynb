{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_excel('data.xlsx')\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 数据划分\n",
    "train_data = data[: 733]\n",
    "pre_data = data[733: ]\n",
    "train_x = train_data[:, 0: 4]\n",
    "train_y = train_data[:, -1] - 1\n",
    "pre_x = pre_data[:, 0: 4]\n",
    "\n",
    "# 预处理\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(np.concatenate([train_x, pre_x], axis=0))\n",
    "train_x = scaler.transform(train_x)\n",
    "pre_x = scaler.transform(pre_x)\n",
    "train_y = keras.utils.to_categorical(train_y, num_classes=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (733, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-1a847549f721>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m             \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m             \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m             validation_split=0.15)\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[0;32m    817\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    818\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 819\u001B[1;33m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[0;32m    820\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m   def evaluate(self,\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[0;32m    233\u001B[0m           \u001B[0mmax_queue_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    234\u001B[0m           \u001B[0mworkers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 235\u001B[1;33m           use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    237\u001B[0m       \u001B[0mtotal_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_total_number_of_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining_data_adapter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001B[0m in \u001B[0;36m_process_training_inputs\u001B[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m    550\u001B[0m         \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    551\u001B[0m         \u001B[0mcheck_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 552\u001B[1;33m         steps=steps_per_epoch)\n\u001B[0m\u001B[0;32m    553\u001B[0m     (x, y, sample_weights,\n\u001B[0;32m    554\u001B[0m      \u001B[0mval_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_y\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_standardize_user_data\u001B[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001B[0m\n\u001B[0;32m   2381\u001B[0m         \u001B[0mis_dataset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mis_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2382\u001B[0m         \u001B[0mclass_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2383\u001B[1;33m         batch_size=batch_size)\n\u001B[0m\u001B[0;32m   2384\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2385\u001B[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_standardize_tensors\u001B[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001B[0m\n\u001B[0;32m   2487\u001B[0m           \u001B[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2488\u001B[0m           training_utils.check_loss_and_target_compatibility(\n\u001B[1;32m-> 2489\u001B[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001B[0m\u001B[0;32m   2490\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2491\u001B[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001B[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001B[0m in \u001B[0;36mcheck_loss_and_target_compatibility\u001B[1;34m(targets, loss_fns, output_shapes)\u001B[0m\n\u001B[0;32m    782\u001B[0m         raise ValueError('You are passing a target array of shape ' +\n\u001B[0;32m    783\u001B[0m                          \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 784\u001B[1;33m                          \u001B[1;34m' while using as loss `categorical_crossentropy`. '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    785\u001B[0m                          \u001B[1;34m'`categorical_crossentropy` expects '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    786\u001B[0m                          \u001B[1;34m'targets to be binary matrices (1s and 0s) '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: You are passing a target array of shape (733, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "network = keras.models.Sequential()\n",
    "network.add(keras.layers.Dense(4, activation=keras.activations.relu, input_shape=(4, )))\n",
    "network.add(keras.layers.Dense(32, activation=keras.activations.relu))\n",
    "network.add(keras.layers.Dense(32, activation=keras.activations.relu))\n",
    "network.add(keras.layers.Dense(6, activation=keras.activations.softmax))\n",
    "\n",
    "network.compile(optimizer=keras.optimizers.RMSprop(lr=1e-3),\n",
    "                loss=keras.losses.categorical_crossentropy,\n",
    "                metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "network.fit(x=train_x, y=train_y,\n",
    "            epochs=10,\n",
    "            batch_size=64,\n",
    "            validation_split=0.15)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}