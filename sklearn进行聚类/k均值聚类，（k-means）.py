# 最著名的聚类方法是K-means聚类。
# K-均值聚类算法将使用聚类方法（也称为质心）将数据分为K个聚类（用户选择聚类的数量）。
# 这些质心代表每个群集的“中心”。
# 具体来说，集群的质心等于集群内所有数据观测值的平均值。
"""
K均值聚类算法是一个迭代过程。
每次迭代，算法都会将每个数据观测值分配给与观测值最接近质心的聚类（使用常规距离度量）。
然后，它将每个质心更新为等于群集中数据观测值的新平均值。
请注意，在算法开始时，会使用K-means ++算法对簇质心进行随机初始化或（更好）初始化。
当任何数据观察的群集分配中没有更多更改时，群集过程将停止。
"""

import numpy as np
from sklearn.cluster import KMeans

data = np.array([
  [5.1, 3.5, 1.4, 0.2],
  [4.9, 3. , 1.4, 0.2],
  [4.7, 3.2, 1.3, 0.2],
  [4.6, 3.1, 1.5, 0.2],
  [5. , 3.6, 1.4, 0.2],
  [5.4, 3.9, 1.7, 0.4],
  [4.6, 3.4, 1.4, 0.3],
  [5. , 3.4, 1.5, 0.2],
  [4.4, 2.9, 1.4, 0.2],
  [4.9, 3.1, 1.5, 0.1]])
kmeans = KMeans(n_clusters=3)  # 指定聚类为三类
kmeans.fit(data)

print(kmeans.labels_)  # 查看对训练数据的最终聚类结果
print(kmeans.cluster_centers_)  # 查看每一类最终质心所在的位置

test_data = np.array([
  [5. , 3.5, 1.6, 0.3],
  [4.8, 3.2, 1.5, 0.1]])

print(kmeans.predict(test_data))  # 查看分类结果

"""
[1 0 0 0 1 2 0 1 0 0]

[[4.68333333 3.11666667 1.41666667 0.2       ]
 [5.03333333 3.5        1.43333333 0.2       ]
 [5.4        3.9        1.7        0.4       ]]
 
[1 0]
"""